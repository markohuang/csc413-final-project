{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "substantial-heating",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "import librosa\n",
    "import scipy\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "import multiprocessing\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Dense, Dropout, Flatten, BatchNormalization, Input, Embedding, LSTM, GRU\n",
    "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D, Bidirectional, Lambda\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras import backend as K\n",
    "from keras.utils import to_categorical\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import normalize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "funded-mason",
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def display_waveform(waveform, title=\"\", sr=8000):\n",
    "    \"\"\"Display waveform plot and audio play UI.\"\"\"\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    plt.plot(waveform)\n",
    "    ipd.display(ipd.Audio(waveform, rate=sr))\n",
    "\n",
    "def stft3_quick(file_path):\n",
    "    res = []\n",
    "    Y, _ = librosa.load(file_path, sr=22050, res_type='kaiser_fast')\n",
    "    for i in np.arange(0.0, 9.5, 0.5):\n",
    "        y = Y[int(66150*i):min(len(Y),int(66150*(i+1)))]\n",
    "        if y.shape[0] < 66150:\n",
    "            y = np.pad(y, (0, 66150 - y.shape[0]), 'constant')\n",
    "        res.append(np.abs(librosa.stft(y, n_fft=1024, window=scipy.signal.hanning, hop_length=512))[:,:128])\n",
    "    res = np.array(res)\n",
    "    return res, file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reverse-recovery",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultispeakerDataset(Dataset):\n",
    "    def __init__(self, index, path):\n",
    "        self.path = path\n",
    "        self.index = index\n",
    "        self.all_files = [(i, name) for (i, speaker) in enumerate(index) for name in speaker]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        speaker_id, name = self.all_files[index]\n",
    "        speaker_onehot = (np.arange(len(self.index)) == speaker_id).astype(np.long)\n",
    "        audio = np.load(f'{self.path}/{speaker_id}/{name}.npy')\n",
    "        \n",
    "        audio = (audio / np.abs(audio.max())).astype(np.float32)\n",
    "        if audio.shape[0] < 66150:\n",
    "            audio = np.tile(audio, int(np.ceil(66150/audio.shape[0])))\n",
    "        audio = np.abs(librosa.stft(audio[0:66150], n_fft=1024, window=scipy.signal.hanning, hop_length=512))[:,:128]\n",
    "        \n",
    "        return speaker_onehot, audio\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.all_files)\n",
    "\n",
    "    def num_speakers(self):\n",
    "        return len(self.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spread-adult",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = ''\n",
    "with open(f'{data_path}/index.pkl', 'rb') as f:\n",
    "    index = pickle.load(f)\n",
    "\n",
    "train_index = [[_ for o,_ in enumerate(x) if o % 10 != 0] for i, x in enumerate(index) if i < 16]\n",
    "val_index = [x[::10] for i, x in enumerate(index) if i < 16]\n",
    "\n",
    "dataset = MultispeakerDataset(train_index, data_path)\n",
    "valset = MultispeakerDataset(val_index, data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ready-particular",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.array([x[1] for x in dataset])\n",
    "y_test = np.array([x[0] for x in dataset])\n",
    "x_test = x_test.reshape(x_test.shape[0], 128, 513, 1)\n",
    "np.save('x_test', x_test)\n",
    "np.save('y_test', y_test)"
   ]
  },
  {
   "source": [
    "### Training"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bottom-reset",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model():\n",
    "    # code taken and modified from \n",
    "    # https://machinelearningmastery.com/how-to-develop-a-convolutional-neural-network-to-classify-photos-of-dogs-and-cats/\n",
    "    model_name = 'best_rescnnqstft3_b128.h5'\n",
    "    model = load_model(model_name)\n",
    "    \n",
    "    for layer in model.layers:\n",
    "        layer.trainable = False  # mark loaded layers as not trainable\n",
    "        \n",
    "    # replace final layers\n",
    "    flat1 = Flatten()(model.layers[-2].output)\n",
    "    output = Dense(16, activation='softmax')(flat1)\n",
    "\n",
    "    # define new model\n",
    "    model = Model(inputs=model.inputs, outputs=output)\n",
    "\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "valid-month",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = define_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incorporate-position",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint('test_model', monitor='acc', verbose=2, save_best_only=True, mode='max')\n",
    "early_stop = EarlyStopping(monitor='acc', patience=5, mode='max') \n",
    "callbacks_list = [checkpoint, early_stop]\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=128,\n",
    "          epochs=20,\n",
    "          verbose=2,\n",
    "          shuffle=True,\n",
    "          callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "noted-kruger",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('curr_best_vctk.h5')"
   ]
  },
  {
   "source": [
    "### Evaluation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.array([x[1] for x in valset])\n",
    "y_test = np.array([x[0] for x in valset])\n",
    "x_test = x_test.reshape(x_test.shape[0], 128, 513, 1)\n",
    "np.save('x_test', x_test)\n",
    "np.save('y_test', y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('curr_best_vctk.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.evaluate(x_test, y_test, batch_size=128)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python379jvsc74a57bd0cc10739b105ecbce0a56bd9c3a1708e94767c8cc6123de67c57c3ab3b1e1de9d",
   "display_name": "Python 3.7.9 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "metadata": {
   "interpreter": {
    "hash": "cc10739b105ecbce0a56bd9c3a1708e94767c8cc6123de67c57c3ab3b1e1de9d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}