{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "statutory-thong",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, cce: 2.054:   3%|▌                   | 13/428 [00:04<02:02,  3.39it/s]^C\n",
      "epoch: 1, cce: 2.054:   3%|▌                   | 13/428 [00:04<02:17,  3.02it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"main2.py\", line 158, in <module>\n",
      "    loss.backward()\n",
      "  File \"/scratch/ssd001/home/marko/thesis/torch/tensor.py\", line 221, in backward\n",
      "    torch.autograd.backward(self, gradient, retain_graph, create_graph)\n",
      "  File \"/scratch/ssd001/home/marko/thesis/torch/autograd/__init__.py\", line 132, in backward\n",
      "    allow_unreachable=True)  # allow_unreachable flag\n",
      "KeyboardInterrupt\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!python main2.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "structural-scott",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from collections import OrderedDict\n",
    "\n",
    "import os, pickle\n",
    "import argparse\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import librosa\n",
    "import scipy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils import data\n",
    "\n",
    "from dataloader import *\n",
    "import sys\n",
    "DIR = '/h/marko/CSC413/RawNet/python/RawNet2/Pre-trained_model'\n",
    "sys.path.append( DIR )\n",
    "from model_RawNet2_original_code import RawNet as RawNet2\n",
    "\n",
    "from parser import get_args\n",
    "from trainer import *\n",
    "from utils import *\n",
    "\n",
    "from argparse import Namespace\n",
    "import glob, json, argparse\n",
    "\n",
    "MAGIC_NUMBER = 59049 # previously 66150\n",
    "np.random.seed(MAGIC_NUMBER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "durable-vietnamese",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "args = Namespace(**{\n",
    "    \"bs\": 64,\n",
    "    \"lr\": 0.001,\n",
    "    \"nb_samp\": MAGIC_NUMBER,\n",
    "    \"name\": 'fma-trial2',\n",
    "    \"save_dir\": 'DNNs/',\n",
    "    \"DB\": '/',\n",
    "    \"window_size\": 0,\n",
    "    \"wd\": 0.001,\n",
    "    \"epoch\": 60,\n",
    "    \"optimizer\": 'Adam',\n",
    "    \"nb_worker\": 4,\n",
    "    \"temp\": .5,\n",
    "    \"seed\": 12315,\n",
    "    \"load_model_dir\": '/h/marko/CSC413/RawNet/python/RawNet2/Pre-trained_model/rawnet2_best_weights.pt',\n",
    "    \"m_first_conv\": 251,\n",
    "    \"m_in_channels\": 1,\n",
    "    \"m_filts\": [128, [128,128], [128,256], [256,256]],\n",
    "    \"m_blocks\": [2, 4],\n",
    "    \"m_nb_fc_att_node\": [1],\n",
    "    \"m_nb_fc_node\": 1024,\n",
    "    \"m_gru_node\": 1024,\n",
    "    \"m_nb_gru_layer\": 1,\n",
    "    \"m_nb_samp\": MAGIC_NUMBER,\n",
    "    \"amsgrad\": True,\n",
    "    \"make_val_trial\": False,\n",
    "    \"debug\": False,\n",
    "    \"comet_disable\": False,\n",
    "    \"save_best_only\": False,\n",
    "    \"mg\": False,\n",
    "    \"load_model\": True,\n",
    "    \"reproducible\": True,\n",
    "})\n",
    "args.model = {}\n",
    "for k, v in vars(args).items():\n",
    "    if k[:2] == 'm_':\n",
    "        # print(k, v)\n",
    "        args.model[k[2:]] = v\n",
    "args.model['nb_classes'] = 6112"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "irish-edward",
   "metadata": {},
   "source": [
    "### Train set here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "reduced-ivory",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = pd.read_csv('/h/marko/CSC413/labels.csv', index_col=0, squeeze=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "orange-great",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/h/marko/CSC413/fma/fma_npy'\n",
    "all_files = np.array(glob.glob(data_dir+'/*.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "contemporary-jefferson",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(all_files)\n",
    "subset_indices = np.random.choice(n, n//10, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "faced-market",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = all_files[np.setdiff1d(np.arange(n), subset_indices)]\n",
    "val_set = all_files[subset_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "hungry-chemical",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FMADataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, audio_list):\n",
    "        self.audio_list = audio_list\n",
    "        self.n = len(self.audio_list)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n * 19\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        audio_fn = self.audio_list[idx % self.n]\n",
    "        audio = np.load(audio_fn)\n",
    "        offset = (idx // self.n) * ((audio.shape[0]-MAGIC_NUMBER) // 19)\n",
    "        label = label_map[int(audio_fn.split('/')[-1][:6])]\n",
    "        # audio,_ = load(audio_fn, sr=22050, res_type='kaiser_fast', offset = 0, duration = 3.0)\n",
    "        # audio,_ = librosa.load(audio_fn, sr=22050, res_type='kaiser_fast')\n",
    "        return audio[offset:offset+MAGIC_NUMBER], label\n",
    "    \n",
    "class FMADataset_val(torch.utils.data.Dataset):\n",
    "    def __init__(self, audio_list):\n",
    "        self.audio_list = audio_list\n",
    "        self.n = len(self.audio_list)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        audio_fn = self.audio_list[idx]\n",
    "        audio = np.load(audio_fn)\n",
    "        label = label_map[int(audio_fn.split('/')[-1][:6])]\n",
    "        return audio[:MAGIC_NUMBER], label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "baking-robert",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = FMADataset(train_set)\n",
    "trainset_gen = data.DataLoader(\n",
    "    trainset,\n",
    "    batch_size = args.bs,\n",
    "    shuffle = True,\n",
    "    drop_last = True,\n",
    "    num_workers = args.nb_worker)\n",
    "\n",
    "valset = FMADataset_val(val_set)\n",
    "valset_gen = data.DataLoader(\n",
    "    valset,\n",
    "    batch_size = 20,\n",
    "    shuffle = True,\n",
    "    drop_last = True,\n",
    "    num_workers = args.nb_worker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "capital-biology",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set save directory\n",
    "save_dir = args.save_dir + args.name + '/'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "os.makedirs(save_dir+'results/', exist_ok=True)\n",
    "os.makedirs(save_dir+'models/', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "acoustic-architect",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RawNet2(args.model, 'cuda').to('cuda')\n",
    "if args.load_model: model.load_state_dict(torch.load(args.load_model_dir))\n",
    "nb_params = sum([param.view(-1).size()[0] for param in model.parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "subjective-injection",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fc2_gru = nn.Linear(in_features = args.model['nb_fc_node'],\n",
    "    out_features = 16,\n",
    "    bias = True)\n",
    "model.cuda();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "optional-offering",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13379378"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "studied-circumstances",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set ojbective funtions\n",
    "criterion = {}\n",
    "criterion['cce'] = nn.CrossEntropyLoss()\n",
    "\n",
    "#set optimizer\n",
    "params = [\n",
    "    {\n",
    "        'params': [\n",
    "            param for name, param in model.named_parameters()\n",
    "            if 'bn' not in name\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        'params': [\n",
    "            param for name, param in model.named_parameters()\n",
    "            if 'bn' in name\n",
    "        ],\n",
    "        'weight_decay':\n",
    "        0\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fundamental-success",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(params,\n",
    "    lr = args.lr,\n",
    "    weight_decay = args.wd,\n",
    "    amsgrad = args.amsgrad)\n",
    "# if args.load_model: optimizer.load_state_dict(torch.load(args.load_model_opt_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "level-remark",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda = lambda step: keras_lr_decay(step))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bearing-graph",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "spoken-session",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model):\n",
    "    global valset, valset_gen\n",
    "    corr = 0\n",
    "    n = len(valset)\n",
    "    for m_batch, m_label in tqdm(valset_gen):\n",
    "        m_batch, m_label = m_batch.cuda(), m_label.cuda()\n",
    "        output = model(m_batch, m_label)\n",
    "        _, pred = torch.max(output, 1)\n",
    "        corr += (m_label == pred).sum().item()\n",
    "    print(f'accuracy: {corr*100/n:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ahead-trout",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RawNet2(args.model, 'cuda')\n",
    "model.fc2_gru = nn.Linear(in_features = args.model['nb_fc_node'],\n",
    "    out_features = 16,\n",
    "    bias = True)\n",
    "model.load_state_dict(torch.load(save_dir +  f'models/TA_26.pt'))\n",
    "model.cuda();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "impressed-cassette",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 124/124 [00:16<00:00,  7.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 59.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "utility-switch",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "residential-workplace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recent-taste",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 1, cce: 1.661:  99%|█████████▉| 6615/6675 [2:05:58<01:08,  1.15s/it]  "
     ]
    }
   ],
   "source": [
    "device = 'cuda'\n",
    "for epoch in range(args.epoch):\n",
    "    model.train()\n",
    "    corr = 0\n",
    "    with tqdm(total = len(trainset_gen)+1, leave=True) as pbar:\n",
    "        epoch_loss = 0\n",
    "        for m_batch, m_label in trainset_gen:\n",
    "            m_batch, m_label = m_batch.to(device), m_label.to(device)\n",
    "            output = model(m_batch, m_label)\n",
    "            cce_loss = criterion['cce'](output, m_label)\n",
    "            loss = cce_loss\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            lr_scheduler.step()\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            _, pred = torch.max(output, 1)\n",
    "            corr += (m_label == pred).sum().item()\n",
    "            \n",
    "            pbar.set_description(f'epoch: {epoch+1}, cce: {cce_loss:.3f}')\n",
    "            pbar.update(1)\n",
    "                    \n",
    "        epoch_loss /= len(trainset_gen)\n",
    "        pbar.set_description(f'epoch: {epoch+1}, avg loss: {epoch_loss:.3f}, acc: {corr/len(trainset_gen):.2f}')\n",
    "        pbar.update(1)\n",
    "                    \n",
    "    if (epoch+1) % 5 == 0:\n",
    "        torch.save(model.state_dict(), save_dir +  f'models/TA_{epoch+1}.pt')\n",
    "        torch.save(optimizer.state_dict(), save_dir + 'models/best_opt_eval.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legitimate-toyota",
   "metadata": {},
   "source": [
    "### Hyperparameter Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "executed-filter",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate(parametrization={}):\n",
    "    args = parametrization\n",
    "    myIndex = open_dir('index')\n",
    "    myQueryParser = QueryParser(\"file_content\", schema=myIndex.schema, group=qparser.OrGroup)\n",
    "    mySearcher = myIndex.searcher(weighting=BM25F(B=args.get('B', 0.524), K1=args.get('K1', 3)))\n",
    "    res = pyTrecEval(TOPIC_FILE, QRELS_FILE, myQueryParser, mySearcher)\n",
    "    return acc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
