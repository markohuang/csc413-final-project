{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "RawNet_fma.ipynb",
      "provenance": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "structural-scott"
      },
      "source": [
        "from tqdm import tqdm\n",
        "from collections import OrderedDict\n",
        "\n",
        "import os, pickle\n",
        "import argparse\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import librosa\n",
        "import scipy\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils import data\n",
        "\n",
        "import sys\n",
        "\n",
        "DIR = '/CSC413/RawNet/python/RawNet2/Pre-trained_model'\n",
        "sys.path.append( DIR )\n",
        "from models.RawNet2 import RawNet as RawNet2\n",
        "\n",
        "from argparse import Namespace\n",
        "import glob, json, argparse\n",
        "\n",
        "MAGIC_NUMBER = 59049\n",
        "np.random.seed(MAGIC_NUMBER)"
      ],
      "id": "structural-scott",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "durable-vietnamese"
      },
      "source": [
        "parser = argparse.ArgumentParser()\n",
        "args = Namespace(**{\n",
        "    \"bs\": 64,\n",
        "    \"lr\": 0.001,\n",
        "    \"nb_samp\": MAGIC_NUMBER,\n",
        "    \"name\": 'fma-trial2',\n",
        "    \"save_dir\": 'DNNs/',\n",
        "    \"DB\": '/',\n",
        "    \"window_size\": 0,\n",
        "    \"wd\": 0.001,\n",
        "    \"epoch\": 60,\n",
        "    \"optimizer\": 'Adam',\n",
        "    \"nb_worker\": 4,\n",
        "    \"temp\": .5,\n",
        "    \"seed\": 12315,\n",
        "    \"load_model_dir\": '/h/marko/CSC413/RawNet/python/RawNet2/Pre-trained_model/rawnet2_best_weights.pt',\n",
        "    \"m_first_conv\": 251,\n",
        "    \"m_in_channels\": 1,\n",
        "    \"m_filts\": [128, [128,128], [128,256], [256,256]],\n",
        "    \"m_blocks\": [2, 4],\n",
        "    \"m_nb_fc_att_node\": [1],\n",
        "    \"m_nb_fc_node\": 1024,\n",
        "    \"m_gru_node\": 1024,\n",
        "    \"m_nb_gru_layer\": 1,\n",
        "    \"m_nb_samp\": MAGIC_NUMBER,\n",
        "    \"amsgrad\": True,\n",
        "    \"make_val_trial\": False,\n",
        "    \"debug\": False,\n",
        "    \"comet_disable\": False,\n",
        "    \"save_best_only\": False,\n",
        "    \"mg\": False,\n",
        "    \"load_model\": True,\n",
        "    \"reproducible\": True,\n",
        "})\n",
        "args.model = {}\n",
        "for k, v in vars(args).items():\n",
        "    if k[:2] == 'm_':\n",
        "        # print(k, v)\n",
        "        args.model[k[2:]] = v\n",
        "args.model['nb_classes'] = 6112"
      ],
      "id": "durable-vietnamese",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "irish-edward"
      },
      "source": [
        "### Train set here"
      ],
      "id": "irish-edward"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "reduced-ivory"
      },
      "source": [
        "label_map = pd.read_csv('/CSC413/labels.csv', index_col=0, squeeze=True)"
      ],
      "id": "reduced-ivory",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "orange-great"
      },
      "source": [
        "data_dir = '/CSC413/fma/fma_npy'\n",
        "all_files = np.array(glob.glob(data_dir+'/*.npy'))"
      ],
      "id": "orange-great",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "contemporary-jefferson"
      },
      "source": [
        "n = len(all_files)\n",
        "subset_indices = np.random.choice(n, n//10, replace=False)"
      ],
      "id": "contemporary-jefferson",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "faced-market"
      },
      "source": [
        "train_set = all_files[np.setdiff1d(np.arange(n), subset_indices)]\n",
        "val_set = all_files[subset_indices]"
      ],
      "id": "faced-market",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hungry-chemical"
      },
      "source": [
        "class FMADataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, audio_list):\n",
        "        self.audio_list = audio_list\n",
        "        self.n = len(self.audio_list)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.n * 19\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        audio_fn = self.audio_list[idx % self.n]\n",
        "        audio = np.load(audio_fn)\n",
        "        offset = (idx // self.n) * ((audio.shape[0]-MAGIC_NUMBER) // 19)\n",
        "        label = label_map[int(audio_fn.split('/')[-1][:6])]\n",
        "        return audio[offset:offset+MAGIC_NUMBER], label\n",
        "    \n",
        "class FMADataset_val(torch.utils.data.Dataset):\n",
        "    def __init__(self, audio_list):\n",
        "        self.audio_list = audio_list\n",
        "        self.n = len(self.audio_list)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.n\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        audio_fn = self.audio_list[idx]\n",
        "        audio = np.load(audio_fn)\n",
        "        label = label_map[int(audio_fn.split('/')[-1][:6])]\n",
        "        return audio[:MAGIC_NUMBER], label"
      ],
      "id": "hungry-chemical",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "baking-robert"
      },
      "source": [
        "trainset = FMADataset(train_set)\n",
        "trainset_gen = data.DataLoader(\n",
        "    trainset,\n",
        "    batch_size = args.bs,\n",
        "    shuffle = True,\n",
        "    drop_last = True,\n",
        "    num_workers = args.nb_worker)\n",
        "\n",
        "valset = FMADataset_val(val_set)\n",
        "valset_gen = data.DataLoader(\n",
        "    valset,\n",
        "    batch_size = 20,\n",
        "    shuffle = True,\n",
        "    drop_last = True,\n",
        "    num_workers = args.nb_worker)"
      ],
      "id": "baking-robert",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "capital-biology"
      },
      "source": [
        "#set save directory\n",
        "save_dir = args.save_dir + args.name + '/'\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "os.makedirs(save_dir+'results/', exist_ok=True)\n",
        "os.makedirs(save_dir+'models/', exist_ok=True)"
      ],
      "id": "capital-biology",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acoustic-architect"
      },
      "source": [
        "model = RawNet2(args.model, 'cuda').to('cuda')\n",
        "if args.load_model: model.load_state_dict(torch.load(args.load_model_dir))\n",
        "nb_params = sum([param.view(-1).size()[0] for param in model.parameters()])"
      ],
      "id": "acoustic-architect",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "subjective-injection"
      },
      "source": [
        "model.fc2_gru = nn.Linear(in_features = args.model['nb_fc_node'],\n",
        "    out_features = 16,\n",
        "    bias = True)\n",
        "model.cuda();"
      ],
      "id": "subjective-injection",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "studied-circumstances"
      },
      "source": [
        "#set ojbective funtions\n",
        "criterion = {}\n",
        "criterion['cce'] = nn.CrossEntropyLoss()\n",
        "\n",
        "#set optimizer\n",
        "params = [\n",
        "    {\n",
        "        'params': [\n",
        "            param for name, param in model.named_parameters()\n",
        "            if 'bn' not in name\n",
        "        ]\n",
        "    },\n",
        "    {\n",
        "        'params': [\n",
        "            param for name, param in model.named_parameters()\n",
        "            if 'bn' in name\n",
        "        ],\n",
        "        'weight_decay':\n",
        "        0\n",
        "    },\n",
        "]"
      ],
      "id": "studied-circumstances",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fundamental-success"
      },
      "source": [
        "optimizer = torch.optim.Adam(params,\n",
        "    lr = args.lr,\n",
        "    weight_decay = args.wd,\n",
        "    amsgrad = args.amsgrad)"
      ],
      "id": "fundamental-success",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "level-remark"
      },
      "source": [
        "def keras_lr_decay(step, decay = 0.0001):\n",
        "    return 1./(1. + decay * step)\n",
        "\n",
        "lr_scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda = lambda step: keras_lr_decay(step))"
      ],
      "id": "level-remark",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bearing-graph"
      },
      "source": [
        "### Evaluate"
      ],
      "id": "bearing-graph"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "spoken-session"
      },
      "source": [
        "def evaluate(model):\n",
        "    global valset, valset_gen\n",
        "    corr = 0\n",
        "    n = len(valset)\n",
        "    for m_batch, m_label in tqdm(valset_gen):\n",
        "        m_batch, m_label = m_batch.cuda(), m_label.cuda()\n",
        "        output = model(m_batch, m_label)\n",
        "        _, pred = torch.max(output, 1)\n",
        "        corr += (m_label == pred).sum().item()\n",
        "    print(f'accuracy: {corr*100/n:.2f}')"
      ],
      "id": "spoken-session",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahead-trout"
      },
      "source": [
        "model = RawNet2(args.model, 'cuda')\n",
        "model.fc2_gru = nn.Linear(in_features = args.model['nb_fc_node'],\n",
        "    out_features = 16,\n",
        "    bias = True)\n",
        "model.load_state_dict(torch.load(save_dir +  f'models/TA_26.pt'))\n",
        "model.cuda();"
      ],
      "id": "ahead-trout",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "impressed-cassette"
      },
      "source": [
        "evaluate(model)"
      ],
      "id": "impressed-cassette",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "utility-switch"
      },
      "source": [
        "### Train"
      ],
      "id": "utility-switch"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "recent-taste"
      },
      "source": [
        "device = 'cuda'\n",
        "for epoch in range(args.epoch):\n",
        "    model.train()\n",
        "    corr = 0\n",
        "    with tqdm(total = len(trainset_gen)+1, leave=True) as pbar:\n",
        "        epoch_loss = 0\n",
        "        for m_batch, m_label in trainset_gen:\n",
        "            m_batch, m_label = m_batch.to(device), m_label.to(device)\n",
        "            output = model(m_batch, m_label)\n",
        "            cce_loss = criterion['cce'](output, m_label)\n",
        "            loss = cce_loss\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            lr_scheduler.step()\n",
        "            \n",
        "            epoch_loss += loss.item()\n",
        "            _, pred = torch.max(output, 1)\n",
        "            corr += (m_label == pred).sum().item()\n",
        "            \n",
        "            pbar.set_description(f'epoch: {epoch+1}, cce: {cce_loss:.3f}')\n",
        "            pbar.update(1)\n",
        "                    \n",
        "        epoch_loss /= len(trainset_gen)\n",
        "        pbar.set_description(f'epoch: {epoch+1}, avg loss: {epoch_loss:.3f}, acc: {corr/len(trainset_gen):.2f}')\n",
        "        pbar.update(1)\n",
        "                    \n",
        "    if (epoch+1) % 5 == 0:\n",
        "        torch.save(model.state_dict(), save_dir +  f'models/TA_{epoch+1}.pt')\n",
        "        torch.save(optimizer.state_dict(), save_dir + 'models/best_opt_eval.pt')"
      ],
      "id": "recent-taste",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "legitimate-toyota"
      },
      "source": [
        "### Hyperparameter Search"
      ],
      "id": "legitimate-toyota"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "executed-filter"
      },
      "source": [
        "def evaluate(parametrization={}):\n",
        "    args = parametrization\n",
        "    myIndex = open_dir('index')\n",
        "    myQueryParser = QueryParser(\"file_content\", schema=myIndex.schema, group=qparser.OrGroup)\n",
        "    mySearcher = myIndex.searcher(weighting=BM25F(B=args.get('B', 0.524), K1=args.get('K1', 3)))\n",
        "    res = pyTrecEval(TOPIC_FILE, QRELS_FILE, myQueryParser, mySearcher)\n",
        "    return acc"
      ],
      "id": "executed-filter",
      "execution_count": null,
      "outputs": []
    }
  ]
}