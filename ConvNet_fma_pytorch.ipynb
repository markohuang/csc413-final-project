{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from collections import OrderedDict\n",
    "\n",
    "import os, pickle\n",
    "import argparse\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import librosa\n",
    "import scipy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils import data\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from argparse import Namespace\n",
    "import glob, json, argparse\n",
    "\n",
    "MAGIC_NUMBER = 59049 # previously 66150\n",
    "np.random.seed(MAGIC_NUMBER)\n",
    "MAGIC_NUMBER = 66150\n",
    "BATCH_SIZE = 125\n",
    "EPOCHS = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = pd.read_csv(f'/CSC413/labels.csv', index_col=0, squeeze=True)\n",
    "data_dir = f'/CSC413/fma/fma_npy'\n",
    "all_files = np.array(glob.glob(data_dir+'/*.npy'))\n",
    "n = len(all_files)\n",
    "subset_indices = np.random.choice(n, n//10, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split\n",
    "train_set = all_files[np.setdiff1d(np.arange(n), subset_indices)]\n",
    "val_set = all_files[subset_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FMADataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, audio_list):\n",
    "        self.audio_list = audio_list\n",
    "        self.n = len(self.audio_list)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n * 19\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        audio_fn = self.audio_list[idx % self.n]\n",
    "        audio = np.load(audio_fn)\n",
    "        offset = (idx // self.n) * ((audio.shape[0]-MAGIC_NUMBER) // 19)\n",
    "        label = label_map[int(audio_fn.split('/')[-1][:6])]\n",
    "        # audio,_ = load(audio_fn, sr=22050, res_type='kaiser_fast', offset = 0, duration = 3.0)\n",
    "        # audio,_ = librosa.load(audio_fn, sr=22050, res_type='kaiser_fast')\n",
    "        audio = np.abs(librosa.stft(audio[offset:offset+MAGIC_NUMBER], n_fft=1024, window=scipy.signal.hanning, hop_length=512))[:,:128]\n",
    "        return audio, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = FMADataset(train_set)\n",
    "trainset_gen = data.DataLoader(\n",
    "    trainset,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    shuffle = True,\n",
    "    drop_last = True,\n",
    "    num_workers = 4)\n",
    "\n",
    "valset = FMADataset(val_set)\n",
    "valset_gen = data.DataLoader(\n",
    "    valset,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    shuffle = True,\n",
    "    drop_last = True,\n",
    "    num_workers = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, num_class):\n",
    "        super().__init__()\n",
    "\n",
    "        self.cnn1 = nn.Sequential(\n",
    "          nn.BatchNorm2d(1),\n",
    "          nn.Conv2d(1, 256, kernel_size=(4, 513)),\n",
    "          nn.ReLU()\n",
    "        )\n",
    "        self.cnn2 = nn.Sequential(\n",
    "          nn.Conv2d(256, 256, kernel_size=(4,1)),\n",
    "          nn.BatchNorm2d(256),\n",
    "          nn.ReLU()\n",
    "        )\n",
    "        self.cnn3 = nn.Sequential(\n",
    "          nn.Conv2d(256, 256, kernel_size=(4,1)),\n",
    "          nn.BatchNorm2d(256),\n",
    "          nn.ReLU()\n",
    "        )\n",
    "        self.cnn4 = nn.Sequential(\n",
    "          nn.Conv2d(256, 256, kernel_size=(4,1)),\n",
    "          nn.BatchNorm2d(256),\n",
    "          nn.ReLU()\n",
    "        )\n",
    "        self.cnn5 = nn.Sequential(\n",
    "          nn.Conv2d(256, 256, kernel_size=(4,1)),\n",
    "          nn.BatchNorm2d(256),\n",
    "          nn.ReLU()\n",
    "        )\n",
    "        self.pool1 = nn.MaxPool2d((125, 1))\n",
    "        self.pool2 = nn.AvgPool2d((125, 1))\n",
    "\n",
    "        self.drop = nn.Dropout(0.2)\n",
    "\n",
    "        self.dense1 = nn.Sequential(\n",
    "          nn.Linear(1024, 480),\n",
    "          nn.ReLU(),\n",
    "          nn.Dropout(0.2)\n",
    "        )\n",
    "        self.dense2 = nn.Sequential(\n",
    "          nn.Linear(480, 240),\n",
    "          nn.ReLU(),\n",
    "          nn.Dropout(0.2)\n",
    "        )\n",
    "\n",
    "        self.classify = nn.Sequential(\n",
    "          nn.Linear(240, num_class),\n",
    "          nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        layer1 = self.cnn1(x)\n",
    "        \n",
    "        layer2 = self.cnn2(F.pad(layer1, (0,0,2,1)))\n",
    "        layer3 = self.cnn3(F.pad(layer2, (0,0,2,1)))\n",
    "        layer4 = self.cnn4(F.pad(layer3, (0,0,2,1)))\n",
    "        layer5 = self.cnn5(F.pad(layer4, (0,0,2,1)))\n",
    "\n",
    "        layer6 = self.pool1(torch.cat((layer5, layer1), dim=1))\n",
    "        layer7 = self.pool2(torch.cat((layer5, layer1), dim=1))\n",
    "\n",
    "        layer8 = self.drop(torch.cat((layer6, layer7), dim=1)).view(-1, 1024)\n",
    "        layer9 = self.dense1(layer8)\n",
    "        layer10 = self.dense2(layer9)\n",
    "\n",
    "        output = self.classify(layer10)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "model = MyModel4(num_class=16).cuda()\n",
    "model.load_state_dict(torch.load('models/model4fma_1.pt'))\n",
    "model.cuda();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model):\n",
    "    global valset, valset_gen\n",
    "    corr = 0\n",
    "    y_true = torch.empty(0)\n",
    "    y_pred = torch.empty(0)\n",
    "    n = len(valset)\n",
    "    with tqdm(total = len(valset_gen), leave=True) as pbar:\n",
    "        for m_batch, m_label in valset_gen:\n",
    "            m_batch, m_label = m_batch.cuda(), m_label.cuda()\n",
    "            output = model(m_batch.transpose(2,1).unsqueeze(1))\n",
    "            _, pred = torch.max(output, 1)\n",
    "            y_true = torch.cat((y_true, m_label))\n",
    "            y_pred = torch.cat((y_pred, pred))\n",
    "            corr += (m_label == pred).sum().item()\n",
    "            pbar.set_description(f'epoch: {epoch+1}, cce: {cce_loss:.3f}')\n",
    "            pbar.update(1)\n",
    "    print(f'accuracy: {corr*100/n:.2f}, f1: {f1_loss()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 379/379 [03:02<00:00,  2.07it/s]\n"
     ]
    }
   ],
   "source": [
    "# setup y_true y_pred for f1, precision, and recall calculations\n",
    "y_true = torch.empty(0).cuda()\n",
    "y_pred = torch.empty(0).cuda()\n",
    "for m_batch, m_label in tqdm(valset_gen):\n",
    "    m_batch, m_label = m_batch.cuda(), m_label.cuda()\n",
    "    output = model(m_batch.transpose(2,1).unsqueeze(1))\n",
    "    _, pred = torch.max(output, 1)\n",
    "    y_true = torch.cat((y_true, m_label))\n",
    "    y_pred = torch.cat((y_pred, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 45.14\n"
     ]
    }
   ],
   "source": [
    "# Validation accuracy\n",
    "evaluate(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1: 0.00 r: 0.00 p: 0.00\n",
      "f1: 0.00 r: 0.00 p: 0.06\n",
      "f1: 0.00 r: 0.00 p: 0.00\n",
      "f1: 0.00 r: 0.00 p: 0.00\n",
      "f1: 0.60 r: 0.71 p: 0.52\n",
      "f1: 0.14 r: 0.11 p: 0.21\n",
      "f1: 0.00 r: 0.00 p: 0.00\n",
      "f1: 0.00 r: 0.00 p: 0.00\n",
      "f1: 0.00 r: 0.00 p: 0.00\n",
      "f1: 0.00 r: 0.00 p: 0.00\n",
      "f1: 0.00 r: 0.00 p: 0.00\n",
      "f1: 0.00 r: 0.00 p: 0.00\n",
      "f1: 0.00 r: 0.00 p: 0.00\n",
      "f1: 0.59 r: 0.94 p: 0.43\n",
      "f1: 0.00 r: 0.00 p: 0.00\n",
      "f1: 0.00 r: 0.00 p: 0.00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.3281, device='cuda:0')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F1 = 0\n",
    "epsilon = 1e-7\n",
    "for c in range(16):\n",
    "    count = (y_true==c).sum()\n",
    "    tp = (y_pred[y_true==c]==c).sum()\n",
    "    fp = (y_pred[y_true!=c]==c).sum()\n",
    "    fn = (y_pred[y_true==c]!=c).sum()\n",
    "    p = tp/(tp+fp+epsilon)\n",
    "    r = tp/(tp+fn+epsilon)\n",
    "    f1 = 2*(p*r)/(p+r+epsilon)\n",
    "    print(f'f1: {f1.cpu().item():.2f} r: {r.cpu().item():.2f} p: {p.cpu().item():.2f}')\n",
    "    F1 += f1*count\n",
    "F1/y_true.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set save directory\n",
    "save_dir = 'models2/'\n",
    "os.makedirs(save_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 1, cce: 2.729, acc: 26.4:  70%|██████▉   | 2383/3418 [22:59<09:58,  1.73it/s]\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda'\n",
    "model = ConvNet(num_class=16)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "optimizer = torch.optim.Adadelta(model.parameters(), lr=0.001, rho=0.95, eps=1e-7)\n",
    "model.cuda()\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    corr = 0\n",
    "    with tqdm(total = len(trainset_gen)+1, leave=True) as pbar:\n",
    "        epoch_loss = 0\n",
    "        for m_batch, m_label in trainset_gen:\n",
    "            m_batch, m_label = m_batch.to(device), m_label.to(device)\n",
    "            output = model(m_batch.transpose(2,1).unsqueeze(1))\n",
    "            loss = criterion(output, m_label)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            _, pred = torch.max(output, 1)\n",
    "            _corr = (m_label == pred).sum().item()\n",
    "            corr += _corr\n",
    "            \n",
    "            pbar.set_description(f'epoch: {epoch+1}, cce: {loss:.3f}, acc: {_corr*100/BATCH_SIZE}')\n",
    "            pbar.update(1)\n",
    "                    \n",
    "        epoch_loss /= len(trainset_gen)\n",
    "        pbar.set_description(f'epoch: {epoch+1}, avg loss: {epoch_loss:.3f}, acc: {corr*100/len(trainset):.2f}')\n",
    "        pbar.update(1)\n",
    "                    \n",
    "    if (epoch+1) % 1 == 0:\n",
    "        torch.save(model.state_dict(), save_dir +  f'model4fma_{epoch+1}.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
